{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä AML Multi-Dataset Data Visualization\n",
        "\n",
        "This notebook visualizes the preprocessed AML datasets to understand:\n",
        "- Dataset distributions and sizes\n",
        "- AML vs Non-AML ratios\n",
        "- Graph structure and connectivity\n",
        "- Feature distributions\n",
        "- Network topology analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install matplotlib seaborn networkx plotly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project path\n",
        "sys.path.append('/content/drive/MyDrive/LaunDetection')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive (if not already mounted)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed datasets\n",
        "def load_processed_datasets():\n",
        "    \"\"\"Load all processed datasets\"\"\"\n",
        "    processed_path = \"/content/drive/MyDrive/LaunDetection/data/processed\"\n",
        "    \n",
        "    datasets = {}\n",
        "    available_datasets = ['HI-Small', 'LI-Small', 'HI-Medium', 'LI-Medium']\n",
        "    \n",
        "    print(\"üìä Loading Processed Datasets...\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for dataset_name in available_datasets:\n",
        "        try:\n",
        "            # Load the processed data\n",
        "            dataset_path = os.path.join(processed_path, f\"{dataset_name}_processed.pkl\")\n",
        "            \n",
        "            if os.path.exists(dataset_path):\n",
        "                with open(dataset_path, 'rb') as f:\n",
        "                    data = pickle.load(f)\n",
        "                \n",
        "                datasets[dataset_name] = data\n",
        "                print(f\"‚úÖ {dataset_name}: Loaded successfully\")\n",
        "                \n",
        "                # Print basic info\n",
        "                if isinstance(data, dict):\n",
        "                    if 'graph' in data:\n",
        "                        graph = data['graph']\n",
        "                        nodes = graph.number_of_nodes()\n",
        "                        edges = graph.number_of_edges()\n",
        "                        print(f\"   üìä Nodes: {nodes:,}, Edges: {edges:,}\")\n",
        "                        \n",
        "                        if 'edge_labels' in data:\n",
        "                            aml_edges = sum(data['edge_labels'])\n",
        "                            non_aml_edges = len(data['edge_labels']) - aml_edges\n",
        "                            aml_rate = (aml_edges / len(data['edge_labels'])) * 100\n",
        "                            print(f\"   üö® AML Edges: {aml_edges:,} ({aml_rate:.2f}%)\")\n",
        "                            print(f\"   ‚úÖ Non-AML Edges: {non_aml_edges:,}\")\n",
        "                    else:\n",
        "                        print(f\"   üìä Data keys: {list(data.keys())}\")\n",
        "                else:\n",
        "                    print(f\"   üìä Data type: {type(data)}\")\n",
        "            else:\n",
        "                print(f\"‚ùå {dataset_name}: File not found\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå {dataset_name}: Error loading - {str(e)}\")\n",
        "    \n",
        "    return datasets\n",
        "\n",
        "# Load the datasets\n",
        "datasets = load_processed_datasets()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick visualization using the simple script\n",
        "!python quick_data_visualization.py\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
